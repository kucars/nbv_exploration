<?xml version="1.0"?>
<sdf version="1.4">

<model name="floating_sensor">
  <plugin name="floating_sensor_position_plugin" filename="libfloating_sensor_position_plugin.so">
<!--     <namespace>floating_sensor</namespace> -->
  </plugin>

  <pose>0 0 0 0 0 0</pose>
  <static>true</static>

  <!-- LIDAR scanner. Simulates Hokuyo scanner -->
  <link name="laser_link">
    <pose>0 0 0 0 0 0</pose>
    <collision name="camera_collision">
      <geometry>
        <box>
          <size>0.2 0.1 0.1</size>
        </box>
      </geometry>
    </collision>

    <visual name="laser_visual">
      <geometry>
        <box>
          <size>0.2 0.1 0.1</size>
        </box>
        <!--
        <mesh>
          <scale>1 1 1</scale>
          <uri>model://rotors_description/meshes/hokuyo.dae</uri>
        </mesh>
        -->
      </geometry>
      <material>
          <ambient>1 0 0 1</ambient>
          <diffuse>1 0 0 1</diffuse>
          <specular>1 0 0 1</specular>
      </material>
    </visual>

    <sensor type="gpu_ray" name="floating_sensor_laser">
      <!-- 10 degrees downward pitch -->
      <pose>0.1 0 0 0 0.1745 0</pose>
      <visualize>true</visualize>
      <update_rate>40</update_rate>
      <ray>
        <scan>
          <horizontal>
            <samples>720</samples>
            <resolution>1</resolution>
            <min_angle>-1.570796</min_angle>
            <max_angle>1.570796</max_angle>
          </horizontal>
        </scan>
        <range>
          <min>0.10</min>
          <max>30.0</max>
          <resolution>0.01</resolution>
        </range>
        <noise>
          <type>gaussian</type>
          <!-- Noise parameters based on published spec for Hokuyo laser
               achieving "+-30mm" accuracy at range < 10m.  A mean of 0.0m and
               stddev of 0.01m will put 99.7% of samples within 0.03m of the true
               reading. -->
          <mean>0.0</mean>
          <stddev>0.01</stddev>
        </noise>
      </ray>
      <plugin name="gazebo_ros_laser_scanner" filename="libgazebo_ros_gpu_laser.so">
        <gaussianNoise>0.005</gaussianNoise>
        <alwaysOn>true</alwaysOn>
        <topicName>scan</topicName>
        <frameName>laser_frame</frameName>
      </plugin>
    </sensor>
  </link>


  <!-- RGB-D camera (simulates Asus Xtion) -->
  <!-- above drone -->
  <link name="rgbd_link">
        <pose>0.05 0 0.1 0 -0.35 0</pose>
    <collision name="camera_collision">
      <geometry>
        <box>
          <size>0.1 0.1 0.1</size>
        </box>
      </geometry>
    </collision>

    <visual name="rgbd_visual">
      <geometry>
        <box>
          <size>0.1 0.1 0.1</size>
        </box>
      </geometry>
      <material>
          <ambient>0 1 0 1</ambient>
          <diffuse>0 1 0 1</diffuse>
          <specular>0 1 0 1</specular>
      </material>
    </visual>

    <sensor type="depth" name="floating_sensor_camera">
      <always_on>true</always_on>
      <update_rate>20.0</update_rate>
      <camera>
        <horizontal_fov>1.047197</horizontal_fov> <!-- 60 degrees -->
        <image>
          <format>R8G8B8</format>
          <width>640</width>
          <height>480</height>
        </image>
        <clip>
          <near>0.05</near>
          <far>8.0</far>
        </clip>
      </camera>

      <plugin name="floating_sensor_camera" filename="libgazebo_ros_openni_kinect.so">
<!--         <robotNamespace>floating_sensor</robotNamespace> -->
        <cameraName>camera</cameraName>
        <alwaysOn>true</alwaysOn>
        <updateRate>10</updateRate>
        <imageTopicName>rgb/image_raw</imageTopicName>
        <depthImageTopicName>depth/image_raw</depthImageTopicName>
        <pointCloudTopicName>depth/points</pointCloudTopicName>
        <cameraInfoTopicName>rgb/camera_info</cameraInfoTopicName>
        <depthImageCameraInfoTopicName>depth/camera_info</depthImageCameraInfoTopicName>
        <frameName>camera_depth_optical_frame</frameName>
        <baseline>0.1</baseline>
        <distortion_k1>0.0</distortion_k1>
        <distortion_k2>0.0</distortion_k2>
        <distortion_k3>0.0</distortion_k3>
        <distortion_t1>0.0</distortion_t1>
        <distortion_t2>0.0</distortion_t2>
        <pointCloudCutoff>0.5</pointCloudCutoff>
      </plugin>
    </sensor>
  </link>
  
  
  <!-- RGB-D camera2 (simulates Asus Xtion) -->
  <!-- below drone -->
  <link name="rgbd2_link">
        <pose>0.05 0 -0.1 0 0.35 0</pose>
    <collision name="camera2_collision">
      <geometry>
        <box>
          <size>0.1 0.1 0.1</size>
        </box>
      </geometry>
    </collision>

    <visual name="rgbd2_visual">
      <geometry>
        <box>
          <size>0.1 0.1 0.1</size>
        </box>
      </geometry>
      <material>
          <ambient>0 1 0 1</ambient>
          <diffuse>0 1 0 1</diffuse>
          <specular>0 1 0 1</specular>
      </material>
    </visual>

    <sensor type="depth" name="floating_sensor_camera2">
      <always_on>true</always_on>
      <update_rate>20.0</update_rate>
      <camera>
        <horizontal_fov>1.047197</horizontal_fov> <!-- 60 degrees -->
        <image>
          <format>R8G8B8</format>
          <width>640</width>
          <height>480</height>
        </image>
        <clip>
          <near>0.05</near>
          <far>8.0</far>
        </clip>
      </camera>

      <plugin name="floating_sensor_camera2" filename="libgazebo_ros_openni_kinect.so">
<!--         <robotNamespace>floating_sensor</robotNamespace> -->
        <cameraName>camera2</cameraName>
        <alwaysOn>true</alwaysOn>
        <updateRate>10</updateRate>
        <imageTopicName>rgb/image_raw</imageTopicName>
        <depthImageTopicName>depth/image_raw</depthImageTopicName>
        <pointCloudTopicName>depth/points</pointCloudTopicName>
        <cameraInfoTopicName>rgb/camera_info</cameraInfoTopicName>
        <depthImageCameraInfoTopicName>depth/camera_info</depthImageCameraInfoTopicName>
        <frameName>camera2_depth_optical_frame</frameName>
        <baseline>0.1</baseline>
        <distortion_k1>0.0</distortion_k1>
        <distortion_k2>0.0</distortion_k2>
        <distortion_k3>0.0</distortion_k3>
        <distortion_t1>0.0</distortion_t1>
        <distortion_t2>0.0</distortion_t2>
        <pointCloudCutoff>0.5</pointCloudCutoff>
      </plugin>
    </sensor>
  </link>

</model>
</sdf>
